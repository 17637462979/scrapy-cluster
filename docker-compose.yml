version: '2'

services:
  kafka_monitor:
    image: istresearch/scrapy-cluster:kafka-monitor-dev
    depends_on:
      - kafka
      - redis
    restart: always
  redis_monitor:
    image: istresearch/scrapy-cluster:redis-monitor-dev
    depends_on:
      - kafka
      - redis
      - zookeeper
    restart: always
  crawler:
    image: istresearch/scrapy-cluster:crawler-dev
    depends_on:
      - kafka
      - redis
      - zookeeper
      - splash
    restart: always
  rest:
    image: istresearch/scrapy-cluster:rest-dev
    depends_on:
      - kafka
      - redis
    restart: always
    ports:
      - "5343:5343"
  redis:
    image: redis
    ports:
      - "6379"
    restart: always
  zookeeper:
    image: zookeeper
    ports:
      - "2181:2181"
    restart: always
  kafka:
    image: wurstmeister/kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    depends_on:
      - zookeeper
    restart: always
  splash:
    image: scrapinghub/splash:2.3.2
    ports:
      - 8050:8050
    restart: always
    # add --maxrss 1 GB on to normal docker entrypoint command
    entrypoint: python3 /app/bin/splash --proxy-profiles-path /etc/splash/proxy-profiles --js-profiles-path /etc/splash/js-profiles --filters-path /etc/splash/filters --lua-package-path /etc/splash/lua_modules/?.lua --maxrss 1000
